PRANAV SHRIDHAR KOWADKAR
Data Scientist / ML Engineer
SUMMARY	
•	Expert in developing production-grade machine learning systems using TensorFlow, PyTorch, and AWS SageMaker, with 4+ years of experience deploying ML solutions across healthcare, finance, and aerospace domains
•	Proven ability in building scalable data pipelines using Apache Spark, Airflow, and AWS EMR, processing 100GB+ daily data with 92% user satisfaction rates
•	Strong experience in cloud-based distributed systems (AWS, Azure, GCP) with demonstrated success in reducing processing latency by 72% through Spark optimizations
•	Skilled in full-stack data engineering including ETL development, data warehousing (Snowflake), and real-time analytics using Kafka/Elasticsearch
•	Proficient in statistical modeling and predictive analytics, achieving 86.84% accuracy in gravitational wave detection through custom neural architectures
•	Advanced capabilities in SQL optimization (20% query performance gains) and database monitoring using Prometheus/Grafana stack
•	Experience with big data technologies including Hadoop, Databricks, and PySpark for processing 76GB+ astronomical datasets
•	Track record of delivering business impact through data-driven solutions - 22% ROI improvement in healthcare marketing campaigns, 15% user engagement boosts
•	Proven leadership in cross-functional collaboration, training 10+ team members on Airflow adoption and reducing manual efforts by 40%
CONTACT INFORMATION	
Phone: +1 973-704-7623 (US) | +91 727-600-3609 (India)  
Email: pk.kowadkar@gmail.com (US) | ps.kowadkar@gmail.com (India)
Web: linkedin.com/in/pkowadkar | github.com/p-kowadkar

Location: Jersey City, NJ | Pune, MH | Bengaluru, KA
Work Authorization: Indian Citizen (authorized to work throughout India) | F1 STEM OPT (US work authorization)
I am originally from Belagavi, KA... Born in Chikodi KA, and had schooling in Hubbali KA, Belagavi KA, Bangalore KA... 
My Bachelor of Engineering was in Mechanical Engineering from Visvesvaraya Technological University, and Master of Science in Data Science from New Jersey Institute of Technology...

EDUCATION	
•	MS in Data Science from New Jersey Institute of Technology, Newark, NJ
•	BE in Mechanical Engineering from Visvesvaraya Technological University, Belagavi, KA, India

TECHNICAL SKILLS	
•	Programming & Scripting: Python, R, C, C++, C#, SQL, PL/SQL, Unix Shell Scripting, .NET
•	Machine Learning & Data Science: TensorFlow, PyTorch, Keras, Scikit-learn; Fine-tuning & Knowledge Distillation (including transformer architectures, GPT-3.5 integration), Model Quantization (GPTQ/AWQ), Natural Language 	Processing (NLP), Prompt Engineering, Statistical & Predictive Modeling, Data Mining
•	Data Analytics & Visualization: Tableau, PowerBI, Looker Studio, Databricks, Snowflake, Pandas, NumPy, Matplotlib
•	Big Data, Data Engineering & Distributed Systems: Apache Spark, Spark ML, Hadoop, Kafka, Airflow, Distributed Computing, ETL, Data Warehousing, Data Lakes, Delta Lake, Elasticsearch, Redis
•	Cloud & DevOps: AWS (S3, RDS, Lambda, CloudFront, SageMaker, Kinesis), Azure, GCP; Docker, Git, CI/CD, Prometheus, Grafana

EXPERIENCE	

New Jersey Institute of Technology, Newark, NJ
Machine Learning Researcher / Data Analyst / AI Engineer	March 2025 – Present
•	Fine-tuned open-source language models (e.g., Llama 4 Scout 17B, Llama 3.2 3B) for neuroimaging classification tasks using PyTorch, achieving 12% higher accuracy compared to general-purpose LLMs on HCP-derived datasets.
•	Designed custom tokenization pipelines for fMRI time-series data, converting 90k+ voxel signals into sequential embeddings compatible with transformer architectures.
•	Implemented knowledge distillation from larger models (e.g., GPT-3.5) to a distilled variant, reducing inference costs by 40% while maintaining 95% of baseline performance.
•	Integrated attention mechanisms to prioritize clinically relevant brain regions (e.g., default mode network), improving classification interpretability.
•	Quantized fine-tuned models using GPTQ/AWQ techniques, reducing memory footprint by 60% for deployment on edge devices.
•	Achieved F1-score of 0.89 on gender classification using resting-state fMRI data, outperforming traditional ML baselines (SVM: 0.82, Random Forest: 0.79).
Environment: Python, PyTorch, Transformers (HuggingFace), fMRI/Neuroimaging (HCP), Tokenizers, Knowledge Distillation, GPT-3.5, Llama 4 Scout 17B, Llama 3.2 3B, Attention Mechanisms, Clinical NLP, GPTQ, AWQ, Model Quantization, Edge Deployment, Machine Learning, Deep Learning, Model Interpretability

Vandoo LLC dba Vaandu, Newark, NJ 	Nov 2024 - Feb 2025
Programmer Analyst
•	Strengthened Oracle-driven data pipelines using advanced PL/SQL (stored procedures, functions) and Unix scripting, boosting query speeds by 20% and ensuring smoother batch processes for financial data processing
•	Implemented Prometheus metrics collection for Oracle database monitoring, creating custom exporters that captured key performance indicators including query latency, connection pools, and tablespace utilization
•	Enhanced Python code quality through targeted refactoring, cutting review times by 15% and improving deployment stability
•	Developed comprehensive Grafana dashboards visualizing real-time pipeline health metrics, establishing alerting thresholds that reduced system outages by 45% through proactive intervention
•	Built an observability framework for AWS Lambda functions using CloudWatch integration with Grafana, providing end-to-end visibility into data flows from S3 to RDS and enabling rapid troubleshooting of performance bottlenecks
•	Implemented data anonymization and encryption protocols in financial data pipelines, ensuring compliance with regulatory requirements while maintaining data usability for analytic
Environment: Python, Oracle, PL/SQL, AWS (S3, Lambda, CloudWatch, RDS), Grafana, Prometheus, Unix, Data Security

JerseySTEM, Florham Park, NJ 	Feb 2024 - Nov 2024
Data Scientist
•	Implemented advanced SQL queries through SQL Workbench and Python data manipulation libraries (pandas, NumPy) that streamlined data processing, enabling efficient analysis of 1M+ data points
•	Designed and deployed Airflow-based data pipelines on AWS EC2, automating reporting processes, cutting manual efforts by 40% and improving efficiency by 25% across operational tasks
•	Championed Airflow adoption by developing comprehensive documentation and training 10+ team members through hands-on workshops, achieving a 40% boost in workflow automation
•	Created comprehensive Looker Studio dashboards for executive leadership, visualizing program effectiveness and student engagement metrics that drove data-informed strategic decisions
•	Utilized Jira for agile project management, tracking progress, and collaborating with team members to ensure timely completion of tasks and projects
•	Applied Agile methodologies, including Scrum and Kanban, to manage and improve work across human systems, balancing demands with available capacity improving the handling of system-level bottlenecks
•	Designed analytical models to process organizational data similar to payroll and HR systems, identifying patterns and trends that improved resource allocation efficiency by 18%
Environment: Python, SQL, Pandas, NumPy, AWS EC2, Airflow, Looker Studio, Jira, Agile, Scrum, Kanban, HR Analytics

Bayer, Remote, NJ 	Sep 2023 - Dec 2023
Data Engineer
•	Architected end-to-end Databricks pipelines (Spark, Python) to process Snowflake healthcare data, generating 3 marketing personas for targeted advertising, ensuring data accuracy and reliability
•	Developed PowerBI dashboards with DAX calculations to visualize 121+ consumer behavior metrics, improving campaign efficiency with data-driven insights that increased ROI by 22%
•	Enhanced ETL processes for real-time point-of-sale data using Azure Data Factory and Python, utilizing 3 key performance indicators to optimize advertising strategy and boost campaign performance by 18%
•	Collaborated with marketing and sales teams to translate business requirements into technical specifications, ensuring delivered solutions aligned with organizational objectives
•	Created automated data quality monitoring systems that ensured data integrity throughout processing pipelines while maintaining compliance with data privacy regulations
Environment: Python, Databricks, Spark, Snowflake, PowerBI, Azure Data Factory, ETL, SQL, Machine Learning, Data Quality, Compliance

Dassault Systems, India 	Apr 2020 - July 2022
R&D Software Engineer
•	Fixed 10+ critical memory issues in CATIA applications using C/C++ and memory profiling tools, enhancing system stability and reducing crash rates by 20% for enterprise clients
•	Led migration of CATIA applications to Linux environment by resolving 20+ platform-specific errors, cutting migration downtime by 40% and ensuring seamless integration
•	Spearheaded automation of CADAM testing using Python, developing a comprehensive test framework that reduced execution time by over 87% (from 15 minutes to 2 minutes) and improved code coverage by ~35%
•	Automated team performance analytics by developing Python scripts (pandas, matplotlib) to process weekly JSON contribution data into visualized reports, eliminating 3+ hours/week manual Excel work and enabling data-driven team 	decisions
•	Engineered self-service reporting solution that transformed contributor achievements into interactive dashboards, with Apache-hosted platform later adopted by 8+ departments for leadership reviews
•	Implemented statistical analysis techniques to identify patterns in software usage data, providing insights that guided product development priorities
Environment: C/C++, Python, Pandas, Matplotlib, JSON, Linux, CATIA, Apache, Statistical Analysis, Data Visualization

National Aerospace Laboratories, India 	Dec 2019 - Mar 2020
Project Assistant
•	Boosted VTOL UAV design efficiency by 17% through manual CFD simulations and Python statistical analysis of 1500+ wind tunnel data points, enabling optimized wing configuration decisions2
•	Accelerated propulsion modeling by 13% by developing interactive Tableau dashboards with matplotlib/seaborn visualizations for real-time analysis of efficiency parameters2
•	Enhanced propeller performance by 8.5% through CATIA V5 optimization of 12 composite blueprints using 3D scan correlations, achieving MIL-STD structural compliance2
•	Automated manual aerospace calculations by replacing Excel workflows with Python scripts (numpy/pandas), reducing stress-strain report generation from 6 hours → 45 minutes with 99.8% accuracy2
•	Applied machine learning techniques to predict performance characteristics based on design parameters, enabling more efficient iterative design processes
Environment: Python, NumPy, Pandas, Matplotlib, Seaborn, Tableau, CATIA V5, CFD, Statistical Analysis, Data Analytics, Machine Learning

Cognizant Technology Solutions, Pune, India 	Dec 2018 - Oct 2019
Programmer Analyst
•	Modernized legacy banking systems by developing a C# transaction processing engine integrated with SQL Server, reducing manual reconciliation efforts by 75% and enabling 25% faster settlement of ₹1.2M+ daily transactions through automated exception handling2
•	Optimized financial application performance through C# code refactoring using OOP principles and multithreading techniques, cutting transaction batch processing time from 6hrs → 4.5hrs for 50K+ daily records while maintaining 99.9% data integrity2
•	Resolved critical database bottlenecks by redesigning 15+ SQL stored procedures and indexing strategies, reducing query latency by 35% (2.6s → 1.7s average) for client-facing reports in high-traffic financial applications2
•	Developed data analysis scripts to identify patterns in transaction data, providing insights that improved fraud detection capabilities
•	Implemented automated reporting solutions that transformed raw financial data into actionable business intelligence, enabling more informed decision-making
Environment: C#, .NET, SQL Server, OOP, Multithreading, Stored Procedures, Data Analysis, Business Intelligence, Financial Systems, Compliance

PROJECTS	

Scalable Real-time Content Recommendation Engine | AWS, Spark, Airflow, Kafka 
- Engineered a distributed recommendation engine using AWS EMR, Spark MLlib, and collaborative filtering algorithms, processing 100GB+ data daily with sub-second response times and achieving 92% user satisfaction
- Reduced data processing latency by 72% and improved content freshness by 4 hours using Airflow DAGs for orchestration, boosting user engagement and click-through rates by 15%
- Built a serverless microservice architecture using AWS Lambda, API Gateway, and DynamoDB, handling 50,000+ requests per second with 99.99% uptime, ensuring seamless scalability during demand spikes
- Implemented A/B testing framework to continuously evaluate recommendation algorithms, resulting in a 28% improvement in recommendation relevance over the initial baseline
- Designed data logging system with Kafka and Elasticsearch to capture user interactions, enabling real-time personalization and continuous model improvement

Intelligent Financial Document Analysis System | RAG, AWS, Spark, Elasticsearch 
- Developed a Retrieval Augmented Generation (RAG) system with custom vector embeddings to analyze 1M+ financial documents daily, boosting insight generation speed by 58% and enhancing analytical efficiency
- Created domain-specific financial embeddings using BERT and fine-tuning techniques, increasing retrieval accuracy by 37% compared to general-purpose models for financial document classification
- Integrated GPT-4 with domain-specific prompting strategies and guardrails, improving insight relevance by 40% and saving 10+ hours of manual analysis weekly for financial analysts
- Designed sophisticated data pipelines with AWS Step Functions and SageMaker to preprocess, analyze, and extract insights from unstructured financial documents with 95% accuracy
- Implemented comprehensive security measures including encryption, access control, and audit logging to ensure compliance with financial data regulations

Gravitational Wave Detection | Python, Time Series Analysis, TensorFlow/Keras, PySpark 
- Innovated a robust deep learning model using TensorFlow, Keras, and signal processing techniques for gravitational wave detection in LIGO/VIRGO data, achieving an accuracy of 86.84% on test data
- Processed 76GB+ of astronomical time-series data with PySpark and custom transforms, overcoming memory limitations to enable large-scale analysis across distributed computing clusters
- Implemented sophisticated neural architecture combining EfficientNetB7 for feature extraction with custom recurrent neural networks for precise binary classification of gravitational wave signals
- Created an ensemble model approach that improved detection sensitivity by 22% over baseline methods, particularly for low signal-to-noise ratio events
- Developed interactive visualization tools using Plotly and Dash to help physicists explore detection results and analyze waveform characteristics

Interactive Anime Insights Platform | Python, Flask, GitHub CI/CD, Docker  
- Developed a full-stack web application with Flask backend and React frontend, implementing CRUD operations and AnimeDB API integration to deliver real-time updates for 100+ daily user interactions
- Implemented comprehensive GitHub Actions CI/CD pipeline for automated testing (pytest, Jest), code quality checks, and Heroku deployment, reducing deployment errors by 50% and deployment time by 70%
- Containerized the application using Docker and docker-compose for consistent development and production environments, standardizing deployments and cutting setup time by approximately 42%
- Designed and implemented a responsive, accessible UI using React, Redux, and Material-UI, achieving a 98% mobile usability score and 25% improvement in user engagement metrics
- Created a recommendation engine using collaborative filtering and content-based approaches, increasing user session duration by 35% and improving content discovery metrics

EDUCATION	

Master of Science | Data Science | GPA: 3.6	Sep 2022 – Dec 2023
New Jersey Institute of Technology, Newark, NJ	
Big Data, Data Analytics with R, Data Structures, Cloud Computing, Data Mining, Machine Learning, Deep Learning, Applied Statistics, Web Development, Capstone Project  
Academic Roles: Teaching Assistant (Big Data, Data Structures), Physics Lab Assistant

Bachelor of Engineering | Mechanical Engineering | GPA: 3.3	Aug 2014 – Jul 2018
Visvesvaraya Technological University, Belagavi, Karnataka
Relevant Projects: UAV Design & Development, Engineering Mechanics, Fluid Dynamics, Robotics, Control Systems, Thermodynamics, Industrial Engineering, Manufacturing, CAD/CAM, CFD, Programming in C